{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7077877-5e9d-4f35-8499-5e317500718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4d67d6-8bf1-45a0-b7c4-51f010ab1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd86ad0a-4bc1-4209-8301-63afbf7e25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796d66a2-168e-43a8-ac4a-1de419bdc8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['b_per'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03eaf17e-c640-4dd5-a561-5236e7c7f442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>b_per</th>\n",
       "      <th>i_per</th>\n",
       "      <th>sentence_normalized</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>key_words</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaargh), but the fact that the raw material is...</td>\n",
       "      <td>Aaargh</td>\n",
       "      <td>Grisham</td>\n",
       "      <td>aaargh but the fact that the raw material is a...</td>\n",
       "      <td>[aaargh, but, the, fact, that, the, raw, mater...</td>\n",
       "      <td>aaargh fact raw material john grisham tale exc...</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I cannot say that Aag is the worst Bollywood f...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i cannot say that aag is the worst bollywood f...</td>\n",
       "      <td>[i, cannot, say, that, aag, is, the, worst, bo...</td>\n",
       "      <td>cannot aag worst bollywood film havent seen bo...</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And if you valued music more than story the li...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>Naam</td>\n",
       "      <td>and if you valued music more than story the li...</td>\n",
       "      <td>[and, if, you, valued, music, more, than, stor...</td>\n",
       "      <td>valued music story list simply grow beautiful ...</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Aag does is take these characters and mes...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what aag does is take these characters and mes...</td>\n",
       "      <td>[what, aag, does, is, take, these, characters,...</td>\n",
       "      <td>aag characters mess badly ull need contest pic...</td>\n",
       "      <td>-0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enough of stupid characters in your movie like...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enough of stupid characters in your movie like...</td>\n",
       "      <td>[enough, of, stupid, characters, in, your, mov...</td>\n",
       "      <td>stupid characters movie like shiva aag</td>\n",
       "      <td>-0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   b_per    i_per  \\\n",
       "0  Aaargh), but the fact that the raw material is...  Aaargh  Grisham   \n",
       "1  I cannot say that Aag is the worst Bollywood f...     Aag      NaN   \n",
       "2  And if you valued music more than story the li...     Aag     Naam   \n",
       "3  What Aag does is take these characters and mes...     Aag      NaN   \n",
       "4  Enough of stupid characters in your movie like...     Aag      NaN   \n",
       "\n",
       "                                 sentence_normalized  \\\n",
       "0  aaargh but the fact that the raw material is a...   \n",
       "1  i cannot say that aag is the worst bollywood f...   \n",
       "2  and if you valued music more than story the li...   \n",
       "3  what aag does is take these characters and mes...   \n",
       "4  enough of stupid characters in your movie like...   \n",
       "\n",
       "                                           tokenizer  \\\n",
       "0  [aaargh, but, the, fact, that, the, raw, mater...   \n",
       "1  [i, cannot, say, that, aag, is, the, worst, bo...   \n",
       "2  [and, if, you, valued, music, more, than, stor...   \n",
       "3  [what, aag, does, is, take, these, characters,...   \n",
       "4  [enough, of, stupid, characters, in, your, mov...   \n",
       "\n",
       "                                           key_words     score  \n",
       "0  aaargh fact raw material john grisham tale exc...  0.023077  \n",
       "1  cannot aag worst bollywood film havent seen bo...  0.027778  \n",
       "2  valued music story list simply grow beautiful ...  0.416667  \n",
       "3  aag characters mess badly ull need contest pic... -0.625000  \n",
       "4             stupid characters movie like shiva aag -0.800000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b3deb74-303e-49cd-9772-daa1ec37299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a954807-1923-4738-870b-394c213cdc1e",
   "metadata": {},
   "source": [
    "## clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd699b91-b61b-4c1d-8894-340f7695dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a75c3ca-2d24-4943-89ec-0b48788814e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence_normalized'] = data['sentence'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f22fbf-120f-44e7-87fc-469c6b8392c4",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c697a62-84f8-4ce0-b749-1100ddcea942",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = []  \n",
    "for sentence in data[\"sentence_normalized\"].astype(str):  # Ensure all reviews are strings\n",
    "    # Tokenize the review: remove non-alphanumeric characters and split into words\n",
    "    word_tokens = sentence.split()\n",
    "    tokenizer.append(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "286cb200-3197-4710-abfc-d1ab0fd53905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tokenizer\"]=tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca80f00-21ed-4491-bc41-0e5cbfa99322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2b31671-13bd-496c-a307-efc9ed3cbd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'four', 'same', 'well', 'anyway', 'him', 'afterwards', 'will', 'out', 'mine', 'either', 'nine', 'therein', 'made', 'who', 'you', 'have', 'i', 'below', 'these', 'give', 'due', 'everything', 'two', 'from', 'them', 'least', 'thereby', 'five', 'anyhow', 'each', 'under', 'again', 'been', 'for', 'becoming', '‘m', 'there', 'side', 'whether', 'say', 'various', 'somewhere', 'regarding', 'noone', 'it', 'go', 'he', 'whole', 'their', '’ll', 'himself', 'hereafter', 'quite', 'hereupon', 'though', 'with', 'ours', '‘re', 'seeming', 'eleven', 'less', 'many', 'whom', 'of', 'beside', 'here', 'without', 'seem', 'everyone', 'but', 'is', 'however', 'eight', 'therefore', 'since', 'among', 'none', 'whatever', 'before', 'during', 'me', 'get', 'more', 'herein', '’ve', 'whoever', 'others', 'are', 'anywhere', 'as', 'six', 'yet', 'toward', 'an', 'over', 'thence', 'even', 'every', 'while', 'us', 'top', 'name', 'done', 'such', 'between', 'using', 'elsewhere', 'now', 'call', 'along', 'something', 'which', '‘s', \"'ll\", 'first', 'rather', 'otherwise', 'sixty', 'being', 'my', 'hereby', 'nevertheless', 'herself', 'used', 'too', 'always', 'hence', 'alone', 'sometime', 'am', 'n‘t', 'doing', 'together', 'and', 'through', \"n't\", 'after', 'beforehand', 'somehow', 'nor', 'this', 'were', \"'d\", 'what', \"'ve\", '‘ve', 'thus', 'our', 'ever', 'just', 'perhaps', 'wherever', 'bottom', 'whose', 'whereby', 'latter', 'whenever', 'anyone', 'twelve', 'across', 'only', 'yours', 'within', '‘d', 'towards', 'formerly', 'how', 'behind', 'both', 'down', 'where', 'twenty', 'except', 'once', '’re', 'myself', 'to', '’s', 'does', 'ten', \"'s\", 'in', 'really', 'beyond', 'than', 'a', 'becomes', 'last', 'part', 'show', 'almost', 'up', 'still', 'ca', 'whereas', 'about', 'neither', 'yourselves', 'although', 'above', 'did', 'we', 'has', 'another', 'must', 'seems', 'thereupon', 'sometimes', 'thru', 'so', 'front', 'into', 'someone', 'those', 'third', 'when', 'she', 'fifteen', 'move', 'empty', 'per', 'moreover', 'other', 'own', 'would', 'besides', 'three', 're', 'was', 'whence', 'whereafter', 'because', 'throughout', 'any', 'else', 'already', 'be', 'become', 'nowhere', 'amongst', 'keep', 'off', 'some', 'had', 'former', 'may', 'yourself', 'fifty', 'the', 'take', 'forty', 'her', \"'re\", 'upon', 'why', 'very', 'could', 'latterly', 'or', 'ourselves', 'hers', 'should', 'anything', 'they', 'then', 'please', 'several', 'indeed', 'next', 'make', 'thereafter', 'also', 'further', 'whereupon', 'became', 'do', 'via', 'all', 'few', 'serious', 'unless', 'by', 'often', 'seemed', 'that', 'itself', 'put', 'can', 'on', '’m', 'around', 'hundred', 'amount', 'everywhere', 'one', 'themselves', 'back', 'your', 'meanwhile', 'namely', 'might', 'full', 'onto', 'wherein', \"'m\", 'see', 'if', 'enough', 'whither', '‘ll', 'most', 'against', 'at', '’d', 'mostly', 'much', 'his', 'until', 'its'}\n"
     ]
    }
   ],
   "source": [
    "deselect_stop_words = ['n\\'', 'love', 'hate', 'like', 'dislike', 'not', '’t', 'never', 'nobody', 'n’t','cannot','nothing','no']\n",
    "stop_words = set(STOP_WORDS)\n",
    "for w in deselect_stop_words:\n",
    "    if w in stop_words:\n",
    "        stop_words.remove(w)\n",
    "    else:\n",
    "         continue\n",
    "\n",
    "# Now, stop_words contains the default stopwords excluding the ones we deselected\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63bdbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = []\n",
    "for comment in data[\"tokenizer\"]:\n",
    "    filteredComment = [w for w in comment if not (w in stop_words or len(w) <= 1)]  # Remove stop words and short words (<=2)\n",
    "    key_words.append(' '.join(filteredComment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9398eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"key_words\"]=key_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73a2de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82c8b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in data[\"key_words\"]:\n",
    "    score.append(TextBlob(i).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8500ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"score\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e9c6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddfac422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         b_per                                           sentence     score\n",
      "0       Aaargh  Aaargh), but the fact that the raw material is...  0.023077\n",
      "1          Aag  I cannot say that Aag is the worst Bollywood f...  0.027778\n",
      "2         Aage  and Robert Lloyd and Aage Haugland both play a... -0.050000\n",
      "3       Aakash  I watched this movie on march 21 this year.Mus...  0.156731\n",
      "4      Aakrosh  After 'Aakrosh' , this was the second film for...  0.000000\n",
      "...        ...                                                ...       ...\n",
      "16346     yeon  I know the actress Do-yeon Jeon got the Cannes...  1.000000\n",
      "16347  yiannis  Perhaps, one of the most important and enjoyab...  0.313393\n",
      "16348      you  If you are interested in making a reality film...  0.225000\n",
      "16349     yway  ANyway, eventually Batman discovers that he's ...  0.000000\n",
      "16350       zo  But when he himself is hustled by a scraggy, w...  0.084375\n",
      "\n",
      "[16351 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_central_sentence(group):\n",
    "    # Find the median score for the group\n",
    "    median_score = group['score'].median()\n",
    "    # Calculate the absolute difference between the score and the median score\n",
    "    group['abs_diff'] = (group['score'] - median_score).abs()\n",
    "    # Find the row with the smallest absolute difference\n",
    "    central_sentence = group.loc[group['abs_diff'].idxmin()]\n",
    "    return central_sentence[['b_per', 'sentence', 'score']]\n",
    "\n",
    "# Apply the function to each group\n",
    "result = data.groupby('b_per').apply(get_central_sentence).reset_index(drop=True)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cab3d994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_per</th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaargh</td>\n",
       "      <td>Aaargh), but the fact that the raw material is...</td>\n",
       "      <td>0.023077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aag</td>\n",
       "      <td>I cannot say that Aag is the worst Bollywood f...</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aage</td>\n",
       "      <td>and Robert Lloyd and Aage Haugland both play a...</td>\n",
       "      <td>-0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aakash</td>\n",
       "      <td>I watched this movie on march 21 this year.Mus...</td>\n",
       "      <td>0.156731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aakrosh</td>\n",
       "      <td>After 'Aakrosh' , this was the second film for...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     b_per                                           sentence     score\n",
       "0   Aaargh  Aaargh), but the fact that the raw material is...  0.023077\n",
       "1      Aag  I cannot say that Aag is the worst Bollywood f...  0.027778\n",
       "2     Aage  and Robert Lloyd and Aage Haugland both play a... -0.050000\n",
       "3   Aakash  I watched this movie on march 21 this year.Mus...  0.156731\n",
       "4  Aakrosh  After 'Aakrosh' , this was the second film for...  0.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afc9a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3479f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-taxi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
