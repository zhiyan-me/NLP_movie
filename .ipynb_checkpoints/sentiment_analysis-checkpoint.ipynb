{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7077877-5e9d-4f35-8499-5e317500718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e4d67d6-8bf1-45a0-b7c4-51f010ab1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd86ad0a-4bc1-4209-8301-63afbf7e25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796d66a2-168e-43a8-ac4a-1de419bdc8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['b_per'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03eaf17e-c640-4dd5-a561-5236e7c7f442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>b_per</th>\n",
       "      <th>i_per</th>\n",
       "      <th>sentence_normalized</th>\n",
       "      <th>tokenizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaargh), but the fact that the raw material is...</td>\n",
       "      <td>Aaargh</td>\n",
       "      <td>Grisham</td>\n",
       "      <td>aaargh but the fact that the raw material is a...</td>\n",
       "      <td>[aaargh, but, the, fact, that, the, raw, mater...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I cannot say that Aag is the worst Bollywood f...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i cannot say that aag is the worst bollywood f...</td>\n",
       "      <td>[i, cannot, say, that, aag, is, the, worst, bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And if you valued music more than story the li...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>Naam</td>\n",
       "      <td>and if you valued music more than story the li...</td>\n",
       "      <td>[and, if, you, valued, music, more, than, stor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What Aag does is take these characters and mes...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what aag does is take these characters and mes...</td>\n",
       "      <td>[what, aag, does, is, take, these, characters,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enough of stupid characters in your movie like...</td>\n",
       "      <td>Aag</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enough of stupid characters in your movie like...</td>\n",
       "      <td>[enough, of, stupid, characters, in, your, mov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence   b_per    i_per  \\\n",
       "0  Aaargh), but the fact that the raw material is...  Aaargh  Grisham   \n",
       "1  I cannot say that Aag is the worst Bollywood f...     Aag      NaN   \n",
       "2  And if you valued music more than story the li...     Aag     Naam   \n",
       "3  What Aag does is take these characters and mes...     Aag      NaN   \n",
       "4  Enough of stupid characters in your movie like...     Aag      NaN   \n",
       "\n",
       "                                 sentence_normalized  \\\n",
       "0  aaargh but the fact that the raw material is a...   \n",
       "1  i cannot say that aag is the worst bollywood f...   \n",
       "2  and if you valued music more than story the li...   \n",
       "3  what aag does is take these characters and mes...   \n",
       "4  enough of stupid characters in your movie like...   \n",
       "\n",
       "                                           tokenizer  \n",
       "0  [aaargh, but, the, fact, that, the, raw, mater...  \n",
       "1  [i, cannot, say, that, aag, is, the, worst, bo...  \n",
       "2  [and, if, you, valued, music, more, than, stor...  \n",
       "3  [what, aag, does, is, take, these, characters,...  \n",
       "4  [enough, of, stupid, characters, in, your, mov...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b3deb74-303e-49cd-9772-daa1ec37299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a954807-1923-4738-870b-394c213cdc1e",
   "metadata": {},
   "source": [
    "## clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd699b91-b61b-4c1d-8894-340f7695dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a75c3ca-2d24-4943-89ec-0b48788814e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentence_normalized'] = data['sentence'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f22fbf-120f-44e7-87fc-469c6b8392c4",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c697a62-84f8-4ce0-b749-1100ddcea942",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = []  \n",
    "for sentence in data[\"sentence_normalized\"].astype(str):  # Ensure all reviews are strings\n",
    "    # Tokenize the review: remove non-alphanumeric characters and split into words\n",
    "    word_tokens = sentence.split()\n",
    "    tokenizer.append(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "286cb200-3197-4710-abfc-d1ab0fd53905",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"tokenizer\"]=tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca80f00-21ed-4491-bc41-0e5cbfa99322",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'table' from 'wasabi' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlang\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01men\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstop_words\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m STOP_WORDS\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\compat.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy_array\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcPickle\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\util.py:33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ValidationError, create_model  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwasabi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m table  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     cupy,\n\u001b[0;32m     37\u001b[0m     cupy_from_dlpack,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     has_torch_mps,\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mxnet \u001b[38;5;28;01mas\u001b[39;00m mx\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'table' from 'wasabi' (unknown location)"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b31671-13bd-496c-a307-efc9ed3cbd39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
